{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoordinats(person,sentence,NER):\n",
    "    \n",
    "    start = sentence.find(person)\n",
    "    end = start + len(person)\n",
    "    NER.append((start, end, \"PERSON\"))\n",
    "    train_data = [(sentence, {\"entities\" : NER})]\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "setofsentences=[]\n",
    "# Laden der validierten Daten aus dem JSON-Dateiformat\n",
    "with open('SentenceRelationships.json', 'r') as file:\n",
    "    validation_data = json.load(file)\n",
    "#test = validation_data[1]\n",
    "PERSONEN_NER=[]\n",
    "for data in validation_data:\n",
    "    sentence = data['sentence']\n",
    "    entities = data['relationships']\n",
    "    predicted_relationships=[]\n",
    "    for entity in entities:\n",
    "        firstEntity = entity['firstEntity']\n",
    "        #relationshipType = entity['relationshipType'] # bei ner ja eignetlich unn√∂tig\n",
    "        secondEntity = entity['secondEntity']\n",
    "        predicted_relationships.append(firstEntity)\n",
    "        predicted_relationships.append(secondEntity)\n",
    "    predicted_relationships = set(predicted_relationships)\n",
    "    setofsentences.append(sentence)\n",
    "    PERSONEN_NER.append( predicted_relationships)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sansa Stark is the eldest daughter and second child of Lady Catelyn and Lord Eddard Stark, the Warden of the North',\n",
       "  {'entities': [(77, 89, 'PERSON'), (0, 11, 'PERSON')]})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 0\n",
    "training_set=[]\n",
    "while x <= len(setofsentences)-1:\n",
    "   \n",
    "    for persongroup in PERSONEN_NER:\n",
    "        y = 0\n",
    "        NER=[]\n",
    "        for person in persongroup:\n",
    "                traindata = getCoordinats(person,setofsentences[x],NER)\n",
    "                y=y+1\n",
    "                if y == len(persongroup):\n",
    "                    training_set.append(traindata)\n",
    "                    x=x+1\n",
    "\n",
    "\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "training_set=[]\n",
    "while x <= len(setofsentences)-1:\n",
    "   \n",
    "    persongroup = PERSONEN_NER[x]\n",
    "    NER=[]\n",
    "    for person in persongroup:\n",
    "        traindata = getCoordinats(person,setofsentences[x],NER)\n",
    "    training_set.append(traindata)\n",
    "    x=x+1\n",
    "\n",
    "training_set\n",
    "\n",
    "f = open(\"training_set.py\", \"x\")\n",
    "f.write(\"training_data_got = \" +  str(training_set))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
