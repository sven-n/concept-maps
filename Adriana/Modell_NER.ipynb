{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.9.24)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\adriana\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adriana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adriana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"She sits silently during the proceedings, witnessi...\" with entities \"[(101, 106, 'PERSON'), (59, 77, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adriana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Trueborn with Cersei:{Son}\n",
      "Legal, fathered by Jai...\" with entities \"[(522, 532, 'PERSON'), (738, 751, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adriana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"{Rhaenys Targaryen}{Aegon Targaryen}\n",
      "Maternal cou...\" with entities \"[(100, 111, 'PERSON'), (154, 162, 'PERSON'), (139,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adriana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"\"\n",
      "Histories & Lore:\"Greyjoy Rebellion: Robb Stark...\" with entities \"[(40, 50, 'PERSON'), (106, 119, 'PERSON'), (215, 2...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adriana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Histories & Lore:\"Greyjoy Rebellion: Robb Stark\"\"R...\" with entities \"[(324, 336, 'PERSON'), (37, 47, 'PERSON'), (69, 82...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adriana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Her Unsullied trapped at Casterly Rock and Highgar...\" with entities \"[(127, 132, 'PERSON'), (84, 102, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adriana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Near the end of her war, Daenerys Targaryen, Drogo...\" with entities \"[(45, 50, 'PERSON'), (25, 43, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 210.92243891123718}\n",
      "Losses: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 95.30761782827193}\n",
      "Losses: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 56.117632962389834}\n",
      "Losses: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 31.435488634318013}\n",
      "Losses: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 36.02370478763534}\n"
     ]
    }
   ],
   "source": [
    "#! python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "from spacy.training.example import Example #Müssen später vermutlich was anderes nehmen\n",
    "from spacy.training.iob_utils import offsets_to_biluo_tags\n",
    "import random\n",
    "import os\n",
    "from got_2NerTrainingData import training_data_got #sehr viele Warnings\n",
    "#rom training_set import training_data_got #Adriana. Weniger Warnings\n",
    "\n",
    "# Load the base model\n",
    "#nlp = spacy.blank(\"en\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create and add the NER pipeline component\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "for text, annotations in training_data_got:\n",
    "    doc = nlp.make_doc(text)\n",
    "    #biluo_tags = offsets_to_biluo_tags(doc, annotations[\"entities\"]) # Mit Svens Daten ging es nicht\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    optimizer = nlp.create_optimizer()\n",
    "\n",
    "# Perform the training\n",
    "for iteration in range(5):  #10 für die kleine Anzahl. Ansonsten könnte man ja so lange iterieren, bis die Fehler eine gewisse Untergrenze erreicht haben\n",
    "    random.shuffle(training_data_got)\n",
    "    losses = {}\n",
    "    for text, annotations in training_data_got:\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "        nlp.update([example], losses=losses, sgd=optimizer)\n",
    "    print(\"Losses:\", losses)\n",
    "\n",
    "# Save the trained NER model\n",
    "output_dir = os.getcwd()\n",
    "nlp.to_disk(output_dir)\n",
    "\n",
    "# Load the saved model\n",
    "loaded_nlp = spacy.load(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eddard Stark PERSON\n",
      "Jon Snow PERSON\n",
      "Cersei Lannister PERSON\n",
      "Jon Snow PERSON\n",
      "Daenerys Targaryen PERSON\n",
      "Eddard Stark PERSON\n",
      "Rickard Stark PERSON\n",
      "Robert Baratheon PERSON\n",
      "Jon Arryn PERSON\n",
      "Jon Arryn PERSON\n",
      "Rhaegar Targaryen PERSON\n",
      "Jon Snow PERSON\n",
      "Eddard Stark PERSON\n",
      "Jon Arryn PERSON\n",
      "Jon Arryn PERSON\n",
      "Jon Snow PERSON\n",
      "Daenerys Targaryen PERSON\n",
      "Drogo PERSON\n",
      "Jon Snow PERSON\n",
      "Renly Baratheon PERSON\n",
      "Tywin Lannister PERSON\n",
      "Tyrion Lannister PERSON\n",
      "Gregor Clegane PERSON\n",
      "Tywin Lannister PERSON\n",
      "Barristan Selmy PERSON\n",
      "Tyrion Lannister PERSON\n",
      "Daenerys Targaryen PERSON\n",
      "Drogo PERSON\n",
      "Jaime Lannister PERSON\n",
      "Gregor Clegane PERSON\n",
      "Tywin Lannister PERSON\n",
      "Eddard Stark PERSON\n",
      "Robb Stark PERSON\n",
      "Cersei Lannister PERSON\n",
      "Ned Stark PERSON\n",
      "Margaery Tyrell PERSON\n",
      "Renly Baratheon PERSON\n",
      "Rodrik Cassel PERSON\n",
      "Theon Greyjoy PERSON\n",
      "Theon Greyjoy PERSON\n",
      "Gregor Clegane PERSON\n",
      "Jaime Lannister PERSON\n",
      "Tyrion Lannister PERSON\n",
      "Ramsay Bolton PERSON\n",
      "Benjen Stark PERSON\n",
      "Arthur Dayne PERSON\n",
      "Ramsay Bolton PERSON\n",
      "Jon Snow PERSON\n",
      "Jon Snow PERSON\n",
      "Robb Stark PERSON\n",
      "Joffrey Baratheon PERSON\n",
      "Ned Stark PERSON\n",
      "Jon Snow PERSON\n",
      "Eddard Stark PERSON\n",
      "Eddard Stark PERSON\n",
      "Jaime Lannister PERSON\n",
      "Jon Snow PERSON\n",
      "Jon Snow PERSON\n",
      "Tyrion Lannister PERSON\n",
      "Jaime Lannister PERSON\n",
      "Arthur Dayne PERSON\n",
      "Stannis Baratheon PERSON\n",
      "Robert Baratheon PERSON\n",
      "Renly Baratheon PERSON\n",
      "Robert Baratheon PERSON\n",
      "Cersei Lannister PERSON\n",
      "Jon Snow PERSON\n",
      "Eddard Stark PERSON\n",
      "Jon Arryn PERSON\n",
      "Arthur Dayne PERSON\n",
      "Hallis Mollen PERSON\n",
      "Eddard Stark PERSON\n",
      "Daenerys Targaryen PERSON\n",
      "Sansa Stark PERSON\n",
      "Rickon Stark PERSON\n",
      "Jon Snow PERSON\n",
      "Ramsay Bolton PERSON\n",
      "Daenerys Targaryen PERSON\n",
      "Rodrik Stark PERSON\n",
      "Karlon Stark PERSON\n",
      "Rhaegar Targaryen PERSON\n",
      "Aerys II Targaryen PERSON\n",
      "Eddard Stark PERSON\n"
     ]
    }
   ],
   "source": [
    "with open(\"text.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "# Load the saved model\n",
    "loaded_nlp = spacy.load(output_dir)\n",
    "\n",
    "# Test the loaded NER model\n",
    "doc = loaded_nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_) #Laut Recherche leer, weil Datensatz zu klein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sentence': 'Queen Sansa Stark is the eldest daughter of Lord Eddard Stark and his wife, Lady Catelyn, sister of Robb, Arya, Bran, and Rickon Stark, and \"half-sister\" of Jon Snow; though truthfully is his cousin', 'relationships': [{'firstEntity': 'Sansa Stark', 'relationshipType': 'Father', 'secondEntity': 'Eddard Stark'}, {'firstEntity': 'Sansa Stark', 'relationshipType': 'Siblings', 'secondEntity': 'Jon Snow'}, {'firstEntity': 'Sansa Stark', 'relationshipType': 'Siblings', 'secondEntity': 'Rickon Stark'}, {'firstEntity': 'Jon Snow', 'relationshipType': 'Father', 'secondEntity': 'Eddard Stark'}, {'firstEntity': 'Eddard Stark', 'relationshipType': 'Children', 'secondEntity': 'Jon Snow'}, {'firstEntity': 'Eddard Stark', 'relationshipType': 'Children', 'secondEntity': 'Sansa Stark'}, {'firstEntity': 'Eddard Stark', 'relationshipType': 'Children', 'secondEntity': 'Rickon Stark'}, {'firstEntity': 'Rickon Stark', 'relationshipType': 'Father', 'secondEntity': 'Eddard Stark'}, {'firstEntity': 'Rickon Stark', 'relationshipType': 'Siblings', 'secondEntity': 'Jon Snow'}, {'firstEntity': 'Rickon Stark', 'relationshipType': 'Siblings', 'secondEntity': 'Sansa Stark'}, {'firstEntity': 'Sansa Stark', 'relationshipType': 'Father', 'secondEntity': 'Eddard Stark'}, {'firstEntity': 'Sansa Stark', 'relationshipType': 'Siblings', 'secondEntity': 'Jon Snow'}, {'firstEntity': 'Sansa Stark', 'relationshipType': 'Siblings', 'secondEntity': 'Rickon Stark'}, {'firstEntity': 'Sansa Stark', 'relationshipType': 'Father', 'secondEntity': 'Eddard Stark'}, {'firstEntity': 'Sansa Stark', 'relationshipType': 'Siblings', 'secondEntity': 'Jon Snow'}, {'firstEntity': 'Sansa Stark', 'relationshipType': 'Siblings', 'secondEntity': 'Rickon Stark'}, {'firstEntity': 'Sansa Stark', 'relationshipType': 'Father', 'secondEntity': 'Eddard Stark'}, {'firstEntity': 'Sansa Stark', 'relationshipType': 'Siblings', 'secondEntity': 'Jon Snow'}, {'firstEntity': 'Sansa Stark', 'relationshipType': 'Siblings', 'secondEntity': 'Rickon Stark'}, {'firstEntity': 'Sansa Stark', 'relationshipType': 'Father', 'secondEntity': 'Eddard Stark'}, {'firstEntity': 'Sansa Stark', 'relationshipType': 'Siblings', 'secondEntity': 'Jon Snow'}, {'firstEntity': 'Sansa Stark', 'relationshipType': 'Siblings', 'secondEntity': 'Rickon Stark'}]}]\n",
      "{'Sansa Stark', 'Jon Snow', 'Rickon Stark', 'Eddard Stark'}\n",
      "Entitäten: Vorhersage stimmt nicht überein\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Laden der validierten Daten aus dem JSON-Dateiformat\n",
    "with open('relationships.json', 'r') as file:\n",
    "    validation_data = json.load(file)\n",
    "\n",
    "# Ausgabe des \"data\" Objekts\n",
    "print(validation_data)\n",
    "\n",
    "# Iteriere über die Sätze im Validierungsdatensatz\n",
    "\n",
    "for data in validation_data:\n",
    "    sentence = data['sentence']\n",
    "    entities = data['relationships']\n",
    "    predicted_relationships=[]\n",
    "    for entity in entities:\n",
    "        firstEntity = entity['firstEntity']\n",
    "        #relationshipType = entity['relationshipType'] # bei ner ja eignetlich unnötig\n",
    "        secondEntity = entity['secondEntity']\n",
    "        predicted_relationships.append(firstEntity)\n",
    "        predicted_relationships.append(secondEntity)\n",
    "    predicted_relationships = set(predicted_relationships)\n",
    "    print(predicted_relationships)\n",
    "    # Verarbeite den Satz mit dem geladenen NER-Modell\n",
    "    doc = loaded_nlp(sentence)\n",
    "\n",
    "    # Vergleiche die vorhergesagten Entitäten mit den tatsächlichen Entitäten\n",
    "    predicted_entities = [(ent.text, ent.label_) for ent in doc.ents] # wird leer sein (war oben schon leer) , benötigen einen größeren Datensatz\n",
    "    if predicted_entities == entities: # geht vermutlich bei arrays nicht\n",
    "        print(\"Entitäten: Vorhersage stimmt überein\")\n",
    "    else:\n",
    "        print(\"Entitäten: Vorhersage stimmt nicht überein\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
