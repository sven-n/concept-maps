{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E002] Can't find factory for 'relation_extractor' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, ner, beam_ner, entity_ruler, tagger, morphologizer, senter, sentencizer, textcat, spancat, spancat_singlelabel, future_entity_ruler, span_ruler, textcat_multilabel, en.lemmatizer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Adriana\\Desktop\\Uni\\Fachpraktikum\\Repos\\rel_component\\text.ipynb Cell 1\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Adriana/Desktop/Uni/Fachpraktikum/Repos/rel_component/text.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Adriana/Desktop/Uni/Fachpraktikum/Repos/rel_component/text.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pfad\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUsers\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mAdriana\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mDesktop\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUni\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mFachpraktikum\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mRepos\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mrel_component\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mtraining\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mmodel-last\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Adriana/Desktop/Uni/Fachpraktikum/Repos/rel_component/text.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(pfad)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Adriana/Desktop/Uni/Fachpraktikum/Repos/rel_component/text.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m text\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mSansa Stark is the daugther of Eddard Stark.\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Adriana/Desktop/Uni/Fachpraktikum/Repos/rel_component/text.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m nlp\u001b[39m.\u001b[39mpipe(text, disable\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mtagger\u001b[39m\u001b[39m\"\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\Adriana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     38\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[0;32m     39\u001b[0m     \u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m     55\u001b[0m         name,\n\u001b[0;32m     56\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m     57\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m     58\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m     59\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m     60\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m     61\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Adriana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:444\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[39mreturn\u001b[39;00m load_model_from_package(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[39mif\u001b[39;00m Path(name)\u001b[39m.\u001b[39mexists():  \u001b[39m# path to model data directory\u001b[39;00m\n\u001b[1;32m--> 444\u001b[0m         \u001b[39mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(name, \u001b[39m\"\u001b[39m\u001b[39mexists\u001b[39m\u001b[39m\"\u001b[39m):  \u001b[39m# Path or Path-like to model data\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Adriana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:516\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    514\u001b[0m overrides \u001b[39m=\u001b[39m dict_to_dot(config)\n\u001b[0;32m    515\u001b[0m config \u001b[39m=\u001b[39m load_config(config_path, overrides\u001b[39m=\u001b[39moverrides)\n\u001b[1;32m--> 516\u001b[0m nlp \u001b[39m=\u001b[39m load_model_from_config(\n\u001b[0;32m    517\u001b[0m     config,\n\u001b[0;32m    518\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m    519\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m    520\u001b[0m     enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m    521\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m    522\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[0;32m    523\u001b[0m )\n\u001b[0;32m    524\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\u001b[39m.\u001b[39mfrom_disk(model_path, exclude\u001b[39m=\u001b[39mexclude, overrides\u001b[39m=\u001b[39moverrides)\n",
      "File \u001b[1;32mc:\\Users\\Adriana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:564\u001b[0m, in \u001b[0;36mload_model_from_config\u001b[1;34m(config, meta, vocab, disable, enable, exclude, auto_fill, validate)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39m# This will automatically handle all codes registered via the languages\u001b[39;00m\n\u001b[0;32m    562\u001b[0m \u001b[39m# registry, including custom subclasses provided via entry points\u001b[39;00m\n\u001b[0;32m    563\u001b[0m lang_cls \u001b[39m=\u001b[39m get_lang_class(nlp_config[\u001b[39m\"\u001b[39m\u001b[39mlang\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m--> 564\u001b[0m nlp \u001b[39m=\u001b[39m lang_cls\u001b[39m.\u001b[39;49mfrom_config(\n\u001b[0;32m    565\u001b[0m     config,\n\u001b[0;32m    566\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m    567\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m    568\u001b[0m     enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m    569\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m    570\u001b[0m     auto_fill\u001b[39m=\u001b[39;49mauto_fill,\n\u001b[0;32m    571\u001b[0m     validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    572\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[0;32m    573\u001b[0m )\n\u001b[0;32m    574\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\n",
      "File \u001b[1;32mc:\\Users\\Adriana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:1803\u001b[0m, in \u001b[0;36mLanguage.from_config\u001b[1;34m(cls, config, vocab, disable, enable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[0;32m   1800\u001b[0m     factory \u001b[39m=\u001b[39m pipe_cfg\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfactory\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1801\u001b[0m     \u001b[39m# The pipe name (key in the config) here is the unique name\u001b[39;00m\n\u001b[0;32m   1802\u001b[0m     \u001b[39m# of the component, not necessarily the factory\u001b[39;00m\n\u001b[1;32m-> 1803\u001b[0m     nlp\u001b[39m.\u001b[39;49madd_pipe(\n\u001b[0;32m   1804\u001b[0m         factory,\n\u001b[0;32m   1805\u001b[0m         name\u001b[39m=\u001b[39;49mpipe_name,\n\u001b[0;32m   1806\u001b[0m         config\u001b[39m=\u001b[39;49mpipe_cfg,\n\u001b[0;32m   1807\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m   1808\u001b[0m         raw_config\u001b[39m=\u001b[39;49mraw_config,\n\u001b[0;32m   1809\u001b[0m     )\n\u001b[0;32m   1810\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1811\u001b[0m     \u001b[39m# We need the sourced components to reference the same\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[39m# vocab without modifying the current vocab state **AND**\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1817\u001b[0m     \u001b[39m# during deserialization, so they do not need any\u001b[39;00m\n\u001b[0;32m   1818\u001b[0m     \u001b[39m# additional handling.\u001b[39;00m\n\u001b[0;32m   1819\u001b[0m     \u001b[39mif\u001b[39;00m vocab_b \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Adriana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:786\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    782\u001b[0m     pipe_component, factory_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_pipe_from_source(\n\u001b[0;32m    783\u001b[0m         factory_name, source, name\u001b[39m=\u001b[39mname\n\u001b[0;32m    784\u001b[0m     )\n\u001b[0;32m    785\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 786\u001b[0m     pipe_component \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_pipe(\n\u001b[0;32m    787\u001b[0m         factory_name,\n\u001b[0;32m    788\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    789\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m    790\u001b[0m         raw_config\u001b[39m=\u001b[39;49mraw_config,\n\u001b[0;32m    791\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    792\u001b[0m     )\n\u001b[0;32m    793\u001b[0m pipe_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_pipe_index(before, after, first, last)\n\u001b[0;32m    794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_meta[name] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_factory_meta(factory_name)\n",
      "File \u001b[1;32mc:\\Users\\Adriana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:660\u001b[0m, in \u001b[0;36mLanguage.create_pipe\u001b[1;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_factory(factory_name):\n\u001b[0;32m    653\u001b[0m     err \u001b[39m=\u001b[39m Errors\u001b[39m.\u001b[39mE002\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    654\u001b[0m         name\u001b[39m=\u001b[39mfactory_name,\n\u001b[0;32m    655\u001b[0m         opts\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactory_names),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    658\u001b[0m         lang_code\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlang,\n\u001b[0;32m    659\u001b[0m     )\n\u001b[1;32m--> 660\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[0;32m    661\u001b[0m pipe_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_factory_meta(factory_name)\n\u001b[0;32m    662\u001b[0m \u001b[39m# This is unideal, but the alternative would mean you always need to\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \u001b[39m# specify the full config settings, which is not really viable.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: [E002] Can't find factory for 'relation_extractor' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, ner, beam_ner, entity_ruler, tagger, morphologizer, senter, sentencizer, textcat, spancat, spancat_singlelabel, future_entity_ruler, span_ruler, textcat_multilabel, en.lemmatizer"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "pfad= \"C:\\\\Users\\\\Adriana\\\\Desktop\\\\Uni\\\\Fachpraktikum\\\\Repos\\\\rel_component\\\\training\\\\model-last\"\n",
    "nlp = spacy.load('en')\n",
    "text=['Sansa Stark is the daugther of Eddard Stark.']\n",
    "for doc in nlp.pipe(text, disable=[\"tagger\"]):\n",
    "   print(f\"spans: {[(e.start, e.text, e.label_) for e in doc.ents]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Adriana\\Desktop\\Uni\\Fachpraktikum\\Repos\\rel_component\\text.ipynb Cell 1\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Adriana/Desktop/Uni/Fachpraktikum/Repos/rel_component/text.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# We take the entities generated from the NER pipeline and input them to the REL pipeline\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Adriana/Desktop/Uni/Fachpraktikum/Repos/rel_component/text.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m name, proc \u001b[39min\u001b[39;00m nlp2\u001b[39m.\u001b[39mpipeline:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Adriana/Desktop/Uni/Fachpraktikum/Repos/rel_component/text.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m           doc \u001b[39m=\u001b[39m proc(doc)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Adriana/Desktop/Uni/Fachpraktikum/Repos/rel_component/text.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Here, we split the paragraph into sentences and apply the relation extraction for each pair of entities found in each sentence.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Adriana/Desktop/Uni/Fachpraktikum/Repos/rel_component/text.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m value, rel_dict \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39m_\u001b[39m.\u001b[39mrel\u001b[39m.\u001b[39mitems():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import typer\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.tokens import DocBin, Doc\n",
    "from spacy.training.example import Example\n",
    "from rel_pipe import make_relation_extractor, score_relations\n",
    "from rel_model import create_relation_model, create_classification_layer, create_instances, create_tensors\n",
    "# We load the relation extraction (REL) model\n",
    "nlp2 = spacy.load(\"training/model-best\")\n",
    "# We take the entities generated from the NER pipeline and input them to the REL pipeline\n",
    "for name, proc in nlp2.pipeline:\n",
    "          doc = proc(doc)\n",
    "# Here, we split the paragraph into sentences and apply the relation extraction for each pair of entities found in each sentence.\n",
    "for value, rel_dict in doc._.rel.items():\n",
    "        for sent in doc.sents:\n",
    "          for e in sent.ents:\n",
    "            for b in sent.ents:\n",
    "              if e.start == value[0] and b.start == value[1]:\n",
    "                if rel_dict['EXPERIENCE_IN'] >=0.9 :\n",
    "                  print(f\" entities: {e.text, b.text} --> predicted relation: {rel_dict}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
